{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "id": "0jPl-T9H0ALO"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, GlobalAveragePooling1D, Dense, LSTM, Dropout\n",
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "from keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "iPJB5TUzi7AO"
      },
      "outputs": [],
      "source": [
        "# Constants for data preprocessing\n",
        "# Constants for data preprocessing\n",
        "max_length = 256  # Maximum length of the sequences\n",
        "padding_type = 'post'  # Padding type for sequences shorter than the maximum length\n",
        "vocab_size = 1000000  # Size of the vocabulary used in the Embedding layer\n",
        "embedding_dim = 64  # Dimensionality of the embedding layer (increased)\n",
        "hidden_units = 64  # Number of hidden units in the LSTM layer (increased)\n",
        "dropout_rate = 0.5  # Dropout rate for regularization\n",
        "\n",
        "# Load the IMDB dataset\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# Helper function to preprocess data\n",
        "def preprocess_data(data):\n",
        "    return pad_sequences(data, maxlen=max_length, padding=padding_type)\n",
        "\n",
        "# Preprocess the data\n",
        "train_data = preprocess_data(train_data)\n",
        "test_data = preprocess_data(test_data)\n",
        "\n",
        "# Define the model architecture\n",
        "def build_model(vocab_size, embedding_dim, hidden_units, dropout_rate):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "        LSTM(hidden_units, dropout=dropout_rate, recurrent_dropout=dropout_rate),  # LSTM layer with dropout\n",
        "        Dense(hidden_units, activation='relu'),\n",
        "        Dropout(dropout_rate),  # Dropout layer for regularization\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "-utAPosijBoP",
        "outputId": "54eb92e4-7ca7-46cc-ba31-8ea78c1472f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build and compile the model\n",
        "model = build_model(vocab_size, embedding_dim, hidden_units, dropout_rate)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c29qQ3OskawF",
        "outputId": "fb24b42b-7a59-4358-be9a-40428ac67150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 - 446s - 570ms/step - accuracy: 0.5309 - loss: 0.6825 - val_accuracy: 0.5619 - val_loss: 0.6534\n",
            "Epoch 2/10\n",
            "782/782 - 426s - 545ms/step - accuracy: 0.5861 - loss: 0.6323 - val_accuracy: 0.5778 - val_loss: 0.6392\n",
            "Epoch 3/10\n",
            "782/782 - 442s - 565ms/step - accuracy: 0.6060 - loss: 0.5924 - val_accuracy: 0.5724 - val_loss: 0.6459\n",
            "Epoch 4/10\n",
            "782/782 - 423s - 541ms/step - accuracy: 0.6232 - loss: 0.5643 - val_accuracy: 0.5841 - val_loss: 0.6525\n",
            "Epoch 5/10\n",
            "782/782 - 442s - 565ms/step - accuracy: 0.6370 - loss: 0.5437 - val_accuracy: 0.6613 - val_loss: 0.6558\n",
            "Epoch 6/10\n",
            "782/782 - 444s - 567ms/step - accuracy: 0.8089 - loss: 0.4375 - val_accuracy: 0.8048 - val_loss: 0.4835\n",
            "Epoch 7/10\n",
            "782/782 - 440s - 562ms/step - accuracy: 0.8550 - loss: 0.3681 - val_accuracy: 0.8146 - val_loss: 0.4552\n",
            "Epoch 8/10\n",
            "782/782 - 441s - 564ms/step - accuracy: 0.8889 - loss: 0.2903 - val_accuracy: 0.8153 - val_loss: 0.4719\n",
            "Epoch 9/10\n",
            "782/782 - 442s - 565ms/step - accuracy: 0.9170 - loss: 0.2288 - val_accuracy: 0.8338 - val_loss: 0.4513\n",
            "Epoch 10/10\n",
            "782/782 - 444s - 568ms/step - accuracy: 0.9398 - loss: 0.1754 - val_accuracy: 0.8153 - val_loss: 0.5183\n",
            "782/782 - 78s - 99ms/step - accuracy: 0.8153 - loss: 0.5183\n",
            "Test Accuracy: 0.815280020236969, Test Loss: 0.5182939171791077\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate the model\n",
        "history = model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(test_data, test_labels), verbose=2)\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels, verbose=2)\n",
        "print(f\"Test Accuracy: {test_acc}, Test Loss: {test_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NrRaTuwrmL2j"
      },
      "outputs": [],
      "source": [
        "#save the model\n",
        "# Save the model to a file\n",
        "model.save('sentiment_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgpDatu2ksR7",
        "outputId": "523c8485-9477-4e67-ac24-f1e80bfa401f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 103ms/step\n",
            "Incorrect Prediction 1:\n",
            "Review: i'm absolutely disgusted this movie isn't being sold all who love this movie should email disney and increase the demand for it they'd eventually have to sell it then i'd buy copies for everybody i know everything and everybody in this movie did a good job and i haven't figured out why disney hasn't put this movie on dvd or on vhs in rental stores at least i haven't seen any copies this is a wicked good movie and should be seen by all the kids in the new generation don't get to see it and i think they should it should at least be put back on the channel this movie doesn't deserve a cheap download it deserves the real thing i'm them now this movie will be on dvd\n",
            "Actual Sentiment: Positive\n",
            "Predicted Sentiment: Negative\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Incorrect Prediction 2:\n",
            "Review: odessa steps the broad expanse of the steps are filled with hundreds of extras rapid and dramatic violence is always suggested and not explicit yet the visual images of the deaths of a few will last in the minds of the viewer forever br br the angular shots of marching boots and legs descending the steps are cleverly accentuated with long menacing shadows from a sun at the top of the steps the pace of the sequence is deliberately varied between the marching soldiers and a few civilians who summon up courage to beg them to stop a close up of a woman's face frozen in horror after being struck by a soldier's sword is the direct antecedent of the bank teller in bonnie in clyde and gives a lasting impression of the horror of the czarist regime br br the death of a young mother leads to a baby carriage careening down the steps in a sequence that has been copied by hitchcock in foreign correspondent by terry gilliam in brazil and brian depalma in the untouchables this sequence is shown repeatedly from various angles thus drawing out what probably was only a five second event br br potemkin is a film that the revolutionary spirit celebrates it for those already committed and it for the unconverted it seethes of fire and roars with the senseless injustices of the decadent czarist regime its greatest impact has been on film students who have borrowed and only slightly improved on techniques invented in russia several generations ago\n",
            "Actual Sentiment: Positive\n",
            "Predicted Sentiment: Negative\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Incorrect Prediction 3:\n",
            "Review: hollywood had a long love affair with bogus arabian nights tales but few of these products have stood the test of time the most memorable were the jon hall maria montez films which have long since become camp this one is filled with dubbed songs anachronistic slang and slapstick it's a truly crop of corn and pretty near intolerable today it was nominated for its imaginative special effects which are almost unnoticeable in this day and age consisting mainly of trick photography the only outstanding positive feature which survives is its beautiful color and clarity sad to say of the many films made in this genre few of them come up to alexander korda's original thief of baghdad almost any other arabian nights film is superior to this one though it's a loser\n",
            "Actual Sentiment: Negative\n",
            "Predicted Sentiment: Positive\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Decode review function\n",
        "word_index = imdb.get_word_index()\n",
        "def decode_review(encoded_review):\n",
        "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review if i >= 3])\n",
        "\n",
        "# Display incorrect predictions\n",
        "def display_incorrect_predictions(test_data, test_labels, predictions, num_examples=3):\n",
        "    predicted_classes = (predictions > 0.5).astype(int)\n",
        "    incorrect_indices = np.where(predicted_classes.flatten() != test_labels)[0]\n",
        "    for i, idx in enumerate(incorrect_indices[:num_examples]):\n",
        "        print(f\"Incorrect Prediction {i+1}:\")\n",
        "        print(f\"Review: {decode_review(test_data[idx])}\")\n",
        "        print(f\"Actual Sentiment: {'Positive' if test_labels[idx] == 1 else 'Negative'}\")\n",
        "        print(f\"Predicted Sentiment: {'Positive' if predicted_classes[idx][0] == 1 else 'Negative'}\")\n",
        "        print(\"--------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "predictions = model.predict(test_data)\n",
        "display_incorrect_predictions(test_data, test_labels, predictions)\n",
        "\n",
        "# Predict sentiments for sample reviews and display them\n",
        "def predict_and_display_reviews(reviews,model_gen):\n",
        "    sequences = [[word_index.get(word, 2) for word in review.lower().split()] for review in reviews]\n",
        "    padded_sequences = preprocess_data(sequences)\n",
        "    sample_predictions = model_gen.predict(padded_sequences)\n",
        "    sample_predicted_classes = (sample_predictions > 0.5).astype(int)\n",
        "    for i, review in enumerate(reviews):\n",
        "        print(f\"Review {i+1}: {review}\")\n",
        "        print(f'Predicted Score: {sample_predictions[i]}')\n",
        "        print(f\"Predicted Sentiment: {'Positive' if sample_predicted_classes[i][0] == 1 else 'Negative'}\")\n",
        "        print(\"--------------------------------------------------------------------------------\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdmv03wikt8a",
        "outputId": "52109512-2090-471f-a386-fb62ccc71ff8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 785 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e2041e39cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step\n",
            "Review 1: nothing was right about the movie. Pathetic story, slow pace, bad dialogues.\n",
            "Predicted Score: [0.9015933]\n",
            "Predicted Sentiment: Positive\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Review 2: This movie was an excellent portrayal of character development and had stellar acting.\n",
            "Predicted Score: [0.9141325]\n",
            "Predicted Sentiment: Positive\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Review 3: I found the movie to be predictable with a lackluster script.\n",
            "Predicted Score: [0.5276026]\n",
            "Predicted Sentiment: Positive\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Review 4: The cinematography was magnificent, and the pacing was perfect. Highly recommend watching.\n",
            "Predicted Score: [0.6266946]\n",
            "Predicted Sentiment: Positive\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Review 5: It was a terrible movie that wasted two hours of my life. The plot made no sense.\n",
            "Predicted Score: [0.9722886]\n",
            "Predicted Sentiment: Positive\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Review 6: An absolute masterpiece, with a gripping story and profound performances.\n",
            "Predicted Score: [0.9441151]\n",
            "Predicted Sentiment: Positive\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sample movie reviews\n",
        "reviews = [\n",
        "    \"nothing was right about the movie. Pathetic story, slow pace, bad dialogues.\",\n",
        "    \"This movie was an excellent portrayal of character development and had stellar acting.\",\n",
        "    \"I found the movie to be predictable with a lackluster script.\",\n",
        "    \"The cinematography was magnificent, and the pacing was perfect. Highly recommend watching.\",\n",
        "    \"It was a terrible movie that wasted two hours of my life. The plot made no sense.\",\n",
        "    \"An absolute masterpiece, with a gripping story and profound performances.\"\n",
        "]\n",
        "model_gen = load_model('sentiment_model.keras')\n",
        "predict_and_display_reviews(reviews,model_gen)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
